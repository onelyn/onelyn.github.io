<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Paper - Empathy || Measures of empathy | LIU Yinuo</title>
<link rel="shortcut icon" href="https://onelyn.github.io/favicon.ico?v=1648087574719">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://onelyn.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="Paper - Empathy || Measures of empathy | LIU Yinuo - Atom Feed" href="https://onelyn.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="Overview

self-report questionnaires
behavioral methods
neuroscience

Self-Report Measures
balanced emotional empathy sc..." />
    <meta name="keywords" content="empathy,paper" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://onelyn.github.io">
  <img class="avatar" src="https://onelyn.github.io/images/avatar.png?v=1648087574719" alt="">
  </a>
  <h1 class="site-title">
    LIU Yinuo
  </h1>
  <p class="site-description">
    
  </p>
  <div class="menu-container">
    
      
        <a href="https://onelyn.github.io" class="menu">
          Homepage
        </a>
      
    
      
        <a href="https://onelyn.github.io/archives" class="menu">
          Research
        </a>
      
    
      
        <a href="https://onelyn.github.io/coursework" class="menu">
          Coursework
        </a>
      
    
  </div>
  <div class="social-container">
    
      
        <a href="https://github.com/onelyn" target="_blank">
          <i class="ri-github-line"></i>
        </a>
      
    
      
        <a href="https://twitter.com/YinuoLIU16" target="_blank">
          <i class="ri-twitter-line"></i>
        </a>
      
    
      
    
      
    
      
    
  </div>

  <p align="left" class="site-description">

    Hello, I'm Yinuo Liu (also call me Nicole). I am an undergraduate student in psychology based at the
    Zhejiang University, China (expected graduation: Autumn 2023).

  </p>
  <p align="left" class="site-description">
    I'm working as a research assistant both in <strong><a href="https://person.zju.edu.cn/0019233" target="_blank">CAI Lab</a></strong>
    and <strong><a href="https://person.zju.edu.cn/konglab" target="_blank">Kong Lab</a></strong>. In CAI Lab, my work focues on the
    feature binding in working memory. In Kong Lab, my work focuses on language brain networks. And I have posted one of my work
    in OBHM 2022 Annual Meeting.

  </p>
  <p align="left" class="site-description">
    You can <i><a href="mailto:zjuonellllyn@gmail.com"> email me</a></i> for anything you are interested in: zjuonellllyn@gmail.com

  </p>

</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              Paper - Empathy || Measures of empathy
            </h2>
            <div class="post-info">
              <span>
                2020-06-19
              </span>
              <span>
                10 min read
              </span>
              
                <a href="https://onelyn.github.io/tag/jG_o9cXEY/" class="post-tag">
                  # empathy
                </a>
              
                <a href="https://onelyn.github.io/tag/HcCMZ9jG8/" class="post-tag">
                  # paper
                </a>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <h2 id="overview">Overview</h2>
<ul>
<li>self-report questionnaires</li>
<li>behavioral methods</li>
<li>neuroscience</li>
</ul>
<h2 id="self-report-measures">Self-Report Measures</h2>
<h3 id="balanced-emotional-empathy-scale-bees">balanced emotional empathy scale (BEES)</h3>
<p>empathy: an increased responsiveness to another's emotional experience</p>
<p>assess the degree to which the respondent can vicariously experience another's happiness or suffering</p>
<p>measures both of the aforementioned components of emotional empathy (vicarious experience of others' feelings; interpersonal positiveness) in a balanced' way.</p>
<p>Gender differences: females tend to obtain higher scores.</p>
<p>limited in emotional empathy, independent of cognitive empathy.</p>
<h3 id="multidimensional-emotional-empathy-scale-mdees">Multidimensional Emotional Empathy Scale (MDEES)</h3>
<p>Focus on the affective component of empathy.  For adolescents and adults.</p>
<p>30 items describing positive and negative emotional situations.</p>
<p>6 sub-scales: empathic suffering, positive sharing, responsive crying, emotional attention, feeling for others, emotional contagion.</p>
<p>Aim to measure different components of affective empathy.</p>
<p>However, Caruso and Mayer against using the emotional contagion sub-scale for it contains only two items. And test-retest reliability of the MDEES remains to be determined.</p>
<h3 id="empathy-quotient-eq">Empathy Quotient (EQ)</h3>
<p>empathy: the drive to identify another person's emotions and thoughts, and to respond to these with an appropriate emotion.</p>
<p>Use scale that measures both cognitive and affective components of empathy.</p>
<p>60 items: 40 empathy items and 20 filler/control items to check for response bias. Half are reverse worded.</p>
<p>Some debate. Some says it aims both cognitive and affective components. Others argue the scale may consist of three factors.  The EQ items tend to focus more on measuring the empathetic process rather than the empathy construct itself.</p>
<h3 id="feeling-and-thinking-scale-fts">Feeling and Thinking Scale (FTS)</h3>
<p>An adaptation of the Interpersonal Reactivity Index (IRI) for use with children. The IRI contains four independent sub-scales: empathic concern, perspective taking, personal distress, fantasy.</p>
<p>Remove reverse items for better comprehension.</p>
<p>4+4+6+4 = 18</p>
<p>Consists of sex differences. Girls show significantly higher scores than boys on both affective and cognitive factors.</p>
<p>During construction of the FTS, a two-factor model reflecting cognitive and affective components of empathy were mainly considered but FTS was based on the four-scale IRI. So the relationship between them should be investigated.</p>
<h3 id="basic-empathy-scale-bes">Basic Empathy Scale (BES)</h3>
<p>Empathy: sharing and understanding of another's emotional state or context resulting from experiencing the emotive state (affective) and understanding another's (cognitive) emotions.</p>
<p>Four basic emotions (fear, sadness, anger, happiness).</p>
<p>The BES has been used in research into bullying and offending.</p>
<p>But little evidence of its stability.</p>
<h3 id="griffith-empathy-measure-gem">Griffith Empathy Measure (GEM)</h3>
<p>Constructed due to the shortage of multi-informant assessment of empathy in children and adolescents.</p>
<p>Assess parents' level of agreement with statements concerning their child.</p>
<p>Measure cognitive and affective components of empathy.</p>
<p>Seems stable but not shows high internal consistency. The principal components analysis extraction increases the risk of falsely inflating component loading.  And it doesn't incorporate a means of systematically reducing response bias.</p>
<h3 id="toronto-empathy-questionnaire-teq">Toronto Empathy Questionnaire (TEQ)</h3>
<p>Did not begin with a conceptual definition of empathy other than to consider it at the broadest level and derive a measure based on existing empathy scales.</p>
<p>Analyzed responses made on every self=report measure of empathy they could identify. And added additional items with altered empathic responding due to neurological or psychiatric disease.</p>
<p>&quot;the broadest, common construct of empathy&quot;</p>
<p>Correlate with IRI components of empathetic concern, perspective taking, fantasy, so it may not need to use multiple sub-scales to measure empathy. But it doesn't correlate with the IRI sub-scale of personal distress.</p>
<h3 id="questionnaire-of-cognitive-and-affective-empathy-qcae">Questionnaire of Cognitive and Affective Empathy (QCAE)</h3>
<p>Aim to build on earlier measures of empathy in which the constructs were considered to be either too narrow or inaccurate, inconsistently defined, or psychometric properties were less than optimal.</p>
<p>Both cognitive and affective are measured.</p>
<p>Items were derived from the EQ and many other questionnaires.</p>
<p>5 sub-scales: perspective taking, online simulation, emotion contagion, proximal中心的 responsivity, peripheral周围的 responsivity.  (first two: cognitive)</p>
<p>Has been used alongside other measures in studies into empathy or music appreciation. The first online measure of empathy to date. But test-retest reliability remains to be determined.</p>
<h2 id="behavioral-measures">Behavioral Measures</h2>
<h3 id="picture-viewing-paradigms-pvp">Picture Viewing Paradigms (PVP)</h3>
<p>empathy: an individual's self-reported response to empathy-eliciting visual images</p>
<p>Images depicting描述 individuals are depicted in certain situations. Often these are negative (injury, grief...) but may also be positive. Image duration is between 6 and 10 seconds. Participants view the images and make a rating response. Ratings may also relate to different components (affective and cognitive) or related constructs (sympathy, distress).</p>
<p>&quot;to what degree you are able to imagine feeling and experiencing what the target is experiencing, in other words, your ability to put yourself in the others' situation&quot;</p>
<p>Also measure corrugator EEG activity and skin conductance responses.</p>
<p>In addition, participants were asked to concentrate on their own feelings while viewing the images or concentrate on the feelings of the target — a &quot;self&quot; versus &quot;other&quot; distinction.</p>
<p>The picture viewing paradigm is commonly employed in experimental research in which experimental manipulations are used (eg. empathy toward different animal types) or in neuroscientific research.</p>
<p>The results depend on the specific way in which empathy-related responding is quantified (eg. self-report versus physiological response).</p>
<h3 id="comic-strip-task-cst">Comic Strip Task (CST)</h3>
<p>Based on how well one can correctly assess other individuals' mental states (desires, intentions, beliefs)</p>
<p>Non-verbal task that presents a series of comic strips连环漫画 and asks participants to choose the best one our of two or three strips on an answer card to finish the story.</p>
<p>&quot;The cartoons that will be presented require you to put yourself in the situation of the main character&quot;</p>
<p>Cognitive empathy condition: choose to make the main character feel better.</p>
<p>Another three conditions.</p>
<p>May be overly simplistic and unable to appropriately estimate cognitive understanding or responsiveness in an empathy inducing situation. And not reflecting &quot;real-life&quot; situations more complex and including multiple persons in.</p>
<p>But it is a real test.</p>
<h3 id="picture-story-stimuli-pss">Picture Story Stimuli (PSS)</h3>
<p>Empathy: the ability to interpret visual scenes and predict the most likely behavioral consequence based on cognitive or affective cues.</p>
<p>The picture comprise two categories depicting two individuals in visually matches aversive (interpersonal attack scenes) and neutral (daily non-emotional scenes) scenes.</p>
<p>Asked either to 'watch' or to 'empathize'.</p>
<p>Colorful arrows to indicate where to watch or empathize.</p>
<p>The validity and reliability remain to be determined.</p>
<h3 id="kids-empathetic-development-scale-keds">Kids Empathetic Development Scale (KEDS)</h3>
<p>Cognitive, affective, behavioral components of empathy are examined using emotion recognition, picture based scenarios and behavioral self-report techniques.</p>
<p>Multidimensional measure of empathy for school-aged children.</p>
<p>The figures are faceless to ensure the measurement of affective inference as opposed to emotion recognition.</p>
<p>Faces incorporate both simple (happy, sad, angry) and complex (relaxed, surprised, afraid) emotions.</p>
<p>Children ascribe one of six emotions presented to a person/s in each of the scenes and they are asked questions.</p>
<p>Try to overcome: how an individual estimates empathy, the simplicity of scenarios in other story based scales, observer and expectancy bias that transpires from self-report measure, language restraints in young children, differences between empathy and sympathy and distress.</p>
<p>But to some extent depends on a child's general verbal comprehension.</p>
<h2 id="neuroscientific-measures">Neuroscientific Measures</h2>
<h3 id="magnetic-resonance-imaging-mri">Magnetic Resonance Imaging (MRI)</h3>
<p>Internal structures of the body including the central nervous system.</p>
<p>The cognitive component of empathy is associated with grey matter volume of the ventral medial Prefrontal Cortex. Affective component is associated with grey matter volume of the inferior frontal gyrus, insula and precuneus.</p>
<p>Can't show the empathic process in action.</p>
<h3 id="functional-magnetic-resonance-imaging-fmri">Functional Magnetic Resonance Imaging (fMRI)</h3>
<p>Provides real-time images of brain activity by detecting increased blood supply and metabolic function (BOLD).</p>
<p>Used with tasks or stimuli that elicit empathy and corresponding brain activation is measured.</p>
<p>Empathy for pain, disgust, threat and pleasantness have been investigated. Research that examines empathy using stimuli depicting facial expressions in different situations or social interactions. But it can be confounded with emotion perception.</p>
<p>And the neuro responses can be related to aversive反感的 responses coupled with motor motor preparation for defensive actions in general.</p>
<h3 id="facial-electromyography-femg">Facial Electromyography (fEMG)</h3>
<p>Can detect muscle activity that occurs below the visual threshold, thus providing a non-verbal index of motor mimicry.</p>
<p>Attach small surface electrodes on the skin over the site of the muscles that play a role in the facial expression of interest.</p>
<p>However, the application of electrodes onto the face may increase awareness of facial expressiveness and lead to exaggerated facial reactions or more general demand characteristics.</p>
<p>And should ensure the motor mimicry reflect the stimuli that is being exposed to and not other stimuli. Like the corrugator EMG can be elicited by non-facial visual stimuli and even sounds.</p>
<h3 id="electroencephalogram-eeg-and-event-related-potentials-erps">Electroencephalogram (EEG) and Event-Related Potentials (ERPs)</h3>
<p>Measure the electrical activity produced by the firing of neurons in the scalp. Short-term changes in the EEG are termed changes in the EEG are termed ERPs.</p>
<p>Can be influenced by physical movement and eye blinks.</p>
<h2 id="future-research-directions">Future Research Directions</h2>
<p>Be measured: different from situation to situation or population to population.</p>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#self-report-measures">Self-Report Measures</a>
<ul>
<li><a href="#balanced-emotional-empathy-scale-bees">balanced emotional empathy scale (BEES)</a></li>
<li><a href="#multidimensional-emotional-empathy-scale-mdees">Multidimensional Emotional Empathy Scale (MDEES)</a></li>
<li><a href="#empathy-quotient-eq">Empathy Quotient (EQ)</a></li>
<li><a href="#feeling-and-thinking-scale-fts">Feeling and Thinking Scale (FTS)</a></li>
<li><a href="#basic-empathy-scale-bes">Basic Empathy Scale (BES)</a></li>
<li><a href="#griffith-empathy-measure-gem">Griffith Empathy Measure (GEM)</a></li>
<li><a href="#toronto-empathy-questionnaire-teq">Toronto Empathy Questionnaire (TEQ)</a></li>
<li><a href="#questionnaire-of-cognitive-and-affective-empathy-qcae">Questionnaire of Cognitive and Affective Empathy (QCAE)</a></li>
</ul>
</li>
<li><a href="#behavioral-measures">Behavioral Measures</a>
<ul>
<li><a href="#picture-viewing-paradigms-pvp">Picture Viewing Paradigms (PVP)</a></li>
<li><a href="#comic-strip-task-cst">Comic Strip Task (CST)</a></li>
<li><a href="#picture-story-stimuli-pss">Picture Story Stimuli (PSS)</a></li>
<li><a href="#kids-empathetic-development-scale-keds">Kids Empathetic Development Scale (KEDS)</a></li>
</ul>
</li>
<li><a href="#neuroscientific-measures">Neuroscientific Measures</a>
<ul>
<li><a href="#magnetic-resonance-imaging-mri">Magnetic Resonance Imaging (MRI)</a></li>
<li><a href="#functional-magnetic-resonance-imaging-fmri">Functional Magnetic Resonance Imaging (fMRI)</a></li>
<li><a href="#facial-electromyography-femg">Facial Electromyography (fEMG)</a></li>
<li><a href="#electroencephalogram-eeg-and-event-related-potentials-erps">Electroencephalogram (EEG) and Event-Related Potentials (ERPs)</a></li>
</ul>
</li>
<li><a href="#future-research-directions">Future Research Directions</a></li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        

        

        <div class="site-footer">
  @YinuoLIU
  <a class="rss" href="https://onelyn.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
